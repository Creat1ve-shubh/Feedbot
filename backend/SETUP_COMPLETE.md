# Brand Perception Backend - Setup Complete! ğŸ‰

## âœ… What's Been Created

Your complete FastAPI + Celery + Redis + PostgreSQL backend is ready!

### ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ app.py                    # FastAPI application entry point
â”œâ”€â”€ celery_app.py            # Celery worker configuration
â”œâ”€â”€ config.py                # Settings & environment configuration
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ docker-compose.yml       # Docker orchestration
â”œâ”€â”€ Dockerfile.api           # API container definition
â”œâ”€â”€ Dockerfile.worker        # Worker container definition
â”œâ”€â”€ .env.example             # Environment template
â”œâ”€â”€ .env                     # Your environment (edit this!)
â”œâ”€â”€ .gitignore              # Git ignore rules
â”‚
â”œâ”€â”€ ğŸ“œ Documentation
â”‚   â”œâ”€â”€ README.md           # Full documentation
â”‚   â””â”€â”€ QUICKSTART.md       # Quick start guide
â”‚
â”œâ”€â”€ ğŸš€ Scripts
â”‚   â”œâ”€â”€ start.ps1           # Start all services
â”‚   â”œâ”€â”€ stop.ps1            # Stop all services
â”‚   â”œâ”€â”€ logs.ps1            # View logs
â”‚   â””â”€â”€ test-api.ps1        # Test the API
â”‚
â”œâ”€â”€ ğŸ›£ï¸ routes/              # API endpoints
â”‚   â”œâ”€â”€ health.py          # Health check endpoint
â”‚   â”œâ”€â”€ analyze.py         # Job queueing endpoint
â”‚   â””â”€â”€ results.py         # Results retrieval endpoint
â”‚
â”œâ”€â”€ ğŸ—„ï¸ db/                  # Database layer
â”‚   â”œâ”€â”€ base.py            # SQLAlchemy setup
â”‚   â”œâ”€â”€ models.py          # Post model definition
â”‚   â””â”€â”€ crud.py            # Database operations
â”‚
â”œâ”€â”€ ğŸ§° utils/               # Utility functions
â”‚   â”œâ”€â”€ clean.py           # Text cleaning utilities
â”‚   â””â”€â”€ context_filter.py  # Context filtering & deduplication
â”‚
â”œâ”€â”€ ğŸ” scrapers/            # Data collection
â”‚   â”œâ”€â”€ reddit_scraper.py  # Reddit data scraper
â”‚   â””â”€â”€ twitter_scraper.py # Twitter data scraper
â”‚
â”œâ”€â”€ ğŸ‘· workers/             # Background processing
â”‚   â””â”€â”€ tasks.py           # Celery task definitions
â”‚
â””â”€â”€ ğŸ§  ml/                  # Machine learning
    â”œâ”€â”€ load_model.py      # Model loading & inference
    â””â”€â”€ batch_infer.py     # Batch processing pipeline
```

## ğŸš€ Next Steps

### 1. Configure API Credentials (Optional but Recommended)

Edit `.env` file and add:

```env
# Reddit API (for Reddit scraping)
REDDIT_CLIENT_ID=your_reddit_client_id
REDDIT_CLIENT_SECRET=your_reddit_secret
REDDIT_USER_AGENT=BrandSentimentApp/0.1

# Twitter API (for Twitter scraping)
TWITTER_BEARER_TOKEN=your_twitter_bearer_token
```

**Don't have credentials yet?** No problem! The system will:
- Work with Reddit only (limited rate without auth)
- Skip Twitter scraping if no token is provided

### 2. Start the Backend

```powershell
# Option A: Use the convenience script
.\start.ps1

# Option B: Manual start
docker compose up --build -d
```

### 3. Verify It's Running

```powershell
# Test the health endpoint
Invoke-RestMethod http://localhost:8000/health

# Or open in browser
start http://localhost:8000/docs
```

### 4. Run Your First Analysis

```powershell
# Option A: Use the test script
.\test-api.ps1

# Option B: Manual test
$body = @{
    brand = "Nike"
    limit = 50
    include_reddit = $true
    include_twitter = $false
} | ConvertTo-Json

Invoke-RestMethod -Uri "http://localhost:8000/analyze" -Method Post -Body $body -ContentType "application/json"
```

## ğŸ“Š What This System Does

### 1. Scraping (Real-time or Background)
- Fetches posts from Reddit & Twitter about your brand
- Cleans and normalizes the text
- Filters out irrelevant posts using keyword context
- Deduplicates to prevent data bloat

### 2. ML Analysis (Batch Processing)
- **Sentiment**: Positive, Negative, or Mixed
- **Confidence**: 0-100% confidence score
- **Emotions**: Joy, Frustration, Neutral
- **Topics**: Pricing, Comfort, Delivery, General
- **Intent**: Query, Complaint, Praise, Feedback
- **Summary**: AI-generated insight
- **Polarity Score**: -1000 to +1000

### 3. Storage & Retrieval
- All data stored in PostgreSQL
- Fast retrieval by brand
- Time-series ordering
- Indexed for performance

## ğŸ¯ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/health` | Check API health |
| POST | `/analyze` | Queue brand analysis job |
| GET | `/results` | Retrieve analyzed posts |
| GET | `/docs` | Interactive API documentation |

## ğŸ”§ Useful Commands

```powershell
# Start services
.\start.ps1

# Stop services
.\stop.ps1

# View logs
.\logs.ps1

# Test API
.\test-api.ps1

# Check status
docker compose ps

# Restart a service
docker compose restart api
docker compose restart worker

# View specific service logs
docker compose logs -f api
docker compose logs -f worker
docker compose logs -f postgres
docker compose logs -f redis
```

## ğŸ—ï¸ Architecture

```
User Request
    â†“
[FastAPI API] â”€â”€â†’ [PostgreSQL]
    â†“                   â†‘
[Redis Queue]           â”‚
    â†“                   â”‚
[Celery Worker] â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
[Reddit/Twitter API]
    â†“
[ML Models]
```

**Flow:**
1. User sends POST to `/analyze` with brand name
2. FastAPI queues job in Redis
3. Celery worker picks up job
4. Worker scrapes Reddit/Twitter
5. Worker runs ML analysis (sentiment, topics, etc.)
6. Worker stores results in PostgreSQL
7. User fetches results via GET `/results`

## âš ï¸ Important Notes

### Common Pitfalls (Already Fixed!)

âœ… **No blocking scraping** - All jobs run in background via Celery
âœ… **Automatic deduplication** - Posts are deduplicated by hash
âœ… **Context filtering** - Only relevant posts are analyzed
âœ… **Batch inference** - ML runs on batches for efficiency
âœ… **Language filtering** - Filters to English posts

### Production Checklist

Before deploying to production:

- [ ] Add real API credentials to `.env`
- [ ] Replace ML placeholders with your trained models
- [ ] Configure proper database backups
- [ ] Set up monitoring (Sentry, DataDog, etc.)
- [ ] Add rate limiting
- [ ] Configure CORS properly
- [ ] Use Docker secrets for credentials
- [ ] Set up CI/CD pipeline
- [ ] Add authentication/authorization

## ğŸ“š Documentation

- **QUICKSTART.md** - Detailed quick start guide
- **README.md** - Full project documentation
- **/docs** - Interactive API docs (http://localhost:8000/docs)

## ğŸ› Troubleshooting

### Services won't start
```powershell
# Check Docker is running
docker --version

# Check port availability
netstat -ano | findstr "8000\|5432\|6379"
```

### No results
1. Check API credentials in `.env`
2. Verify worker is running: `docker compose ps worker`
3. Check worker logs: `docker compose logs worker`
4. Ensure brand name matches exactly

### Database errors
```powershell
docker compose restart postgres
docker compose logs postgres
```

## ğŸ“ Learning Resources

### FastAPI
- Official Docs: https://fastapi.tiangolo.com/
- Tutorial: https://fastapi.tiangolo.com/tutorial/

### Celery
- Official Docs: https://docs.celeryq.dev/
- Best Practices: https://docs.celeryq.dev/en/stable/userguide/tasks.html

### Docker
- Docker Compose: https://docs.docker.com/compose/

## ğŸš€ Extending the System

### Add New Scrapers
1. Create file in `scrapers/` (e.g., `instagram_scraper.py`)
2. Follow the pattern in `reddit_scraper.py`
3. Import in `workers/tasks.py`
4. Add to `scrape_and_analyze` task

### Add New ML Models
1. Replace placeholder models in `ml/load_model.py`
2. Update `batch_infer.py` with your pipeline
3. Retrain models with your Kaggle notebooks
4. Deploy model artifacts to `./models/`

### Add New Brands
Edit `utils/context_filter.py`:
```python
KEY_PHRASES = {
    "nike": ["shoe", "sneaker", "comfort", ...],
    "apple": ["iphone", "macbook", "ios", ...],
    "tesla": ["car", "ev", "autopilot", ...],
}
```

## ğŸ’¡ Tips for Success

1. **Start small** - Test with `limit=10` first
2. **Monitor workers** - Watch `docker compose logs -f worker`
3. **Check health** - Visit `/health` regularly
4. **Use Swagger UI** - http://localhost:8000/docs for testing
5. **Read the logs** - Most issues are visible in logs

## ğŸ‰ You're All Set!

Your brand sentiment analysis backend is ready to go. Start by running:

```powershell
.\start.ps1
```

Then visit http://localhost:8000/docs to explore the API!

---

Need help? Check:
- QUICKSTART.md for detailed guide
- README.md for full documentation
- Docker logs for debugging
